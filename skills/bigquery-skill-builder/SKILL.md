---
name: bigquery-skill-builder
description: Meta-skill that generates custom BigQuery monitoring skills for any table. One-time setup creates a table-specific skill with all metadata baked in, eliminating need to re-enter configuration.
---

# BigQuery Skill Builder (Meta-Skill)

## Overview

This meta-skill generates **custom, table-specific monitoring skills** similar to `ottm-bigquery-debugging`. Provide table metadata **once**, and get a reusable skill forever.

## When to Use

- "Create monitoring skill for {project}.{dataset}.{table}"
- "Generate BigQuery skill for my service logs"
- "Set up monitoring for my error table"

## How It Works

```
1. User requests skill creation for a BigQuery table
2. Builder discovers schema (column names only)
3. Builder asks for configuration (which columns contain errors, timestamps, etc.)
4. Builder generates ~/.claude/skills/{name}-monitor/SKILL.md
5. User can now use generated skill forever without re-entering metadata
```

## Pre-Approved Actions

- BigQuery DESCRIBE queries (schema discovery - column names only)
- Creating new skill directories in ~/.claude/skills/
- Writing skill files (SKILL.md)
- No approval needed for any of these operations

## Instructions

### Step 1: Parse User Request

Extract table information from user's request:
- Project ID
- Dataset name
- Table name
- Optional: Desired skill name (default: {table}-monitor)

**Example inputs**:
- "Create monitoring skill for qtco-messaging-channels.prod.app_logs"
- "Generate skill for my-project.dataset.error_logs called error-monitor"

### Step 2: Discover Table Schema

**Query schema** (column names only, NO data):
```bash
CLOUDSDK_PYTHON_SITEPACKAGES=1 bq query --format=json --use_legacy_sql=false '
DESCRIBE `{project}.{dataset}.{table}`
'
```

**Parse output** to get list of column names and types.

**Display to user**:
```
Table {project}.{dataset}.{table} has {N} columns:
- timestamp (TIMESTAMP)
- level (STRING)
- message (STRING)
- error (STRING)
- request_id (STRING)
- ...
```

### Step 3: Ask for Configuration

Use AskUserQuestion to gather metadata:

**Question 1: Error Column**
- Question: "Which column contains error messages?"
- Detect candidates: columns with names like "error", "exception", "error_message", "error_msg"
- Recommended: First detected column
- Allow "Other" for custom input

**Question 2: Severity/Level Column**
- Question: "Which column contains error severity/level? (optional)"
- Detect candidates: "level", "severity", "log_level", "priority"
- Recommended: First detected column or "None"
- Allow "Other" or skip

**Question 3: Timestamp Column**
- Question: "Which column contains timestamps?"
- Detect candidates: "timestamp", "created_at", "event_time", "time", "datetime"
- Recommended: First detected column
- Allow "Other"

**Question 4: Partition Column (Optional)**
- Question: "Which column is used for partitioning? (for query performance)"
- Detect candidates: "PARTITIONDATE", "PARTITIONTIME", "date", "dt"
- Recommended: First detected or "None"
- Allow "Other" or skip

**Question 5: Identity Column (Optional)**
- Question: "Which column contains request/transaction IDs for correlation?"
- Detect candidates: "request_id", "transaction_id", "trace_id", "id"
- Recommended: First detected or "None"
- Allow "Other" or skip

**Question 6: Skill Name**
- Question: "What should we call this monitoring skill?"
- Default: "{table}-monitor"
- User can customize

### Step 4: Generate Skill File

**Create directory**:
```bash
mkdir -p ~/.claude/skills/{skill_name}
```

**Write SKILL.md**:
```markdown
---
name: {skill_name}
description: Monitor {project}.{dataset}.{table} for errors and bugs. Auto-generated by bigquery-skill-builder.
---

# {Table Name} Monitor

## Pre-Configured Table

**Table**: `{project}.{dataset}.{table}`

**Configuration**:
- **Error Column**: {error_column}
- **Level Column**: {level_column}
- **Timestamp Column**: {timestamp_column}
- **Partition Column**: {partition_column}
- **Identity Column**: {identity_column}

## When to Use

- "Scan {skill_name} for bugs from last N hours"
- "Find {skill_name} errors"
- "Analyze {skill_name} for improvements"
- "Check {skill_name} for new errors"

## Pre-Approved Actions

- BigQuery queries to the configured table
- Reading/writing to /tmp/ for error signature tracking
- Displaying discovered errors
- All actions for scanning and analysis

## Instructions

### Invocation Patterns

User will say things like:
- "Scan {skill_name} for bugs"
- "Check {skill_name} errors from last 4 hours"
- "Find new {skill_name} failures"

### Step 1: Parse Request

Extract parameters:
- Time window (default: 4 hours)
- Specific conditions (optional)

### Step 2: Query BigQuery for Errors

**Query Template**:
```sql
SELECT
  {timestamp_column},
  {error_column},
  {level_column IF PRESENT},
  {identity_column IF PRESENT},
  *
FROM `{project}.{dataset}.{table}`
WHERE {error_column} IS NOT NULL
  {AND partition_filter IF PRESENT}
  AND {timestamp_column} >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {hours} HOUR)
ORDER BY {timestamp_column} DESC
LIMIT 100
```

**Execute query**:
```bash
CLOUDSDK_PYTHON_SITEPACKAGES=1 bq query --format=json --use_legacy_sql=false '<QUERY>'
```

### Step 3: Track Error Signatures

**Load existing signatures**:
```bash
cat /tmp/bigquery_error_signatures_{project}_{dataset}_{table}.json || echo '{}'
```

**For each error**:
1. Extract error message from {error_column}
2. Normalize message:
   - Replace IDs: `[A-Z]{{2}}[a-f0-9]+` → `RESOURCE_ID`
   - Replace numbers: `\\d+` → `NUMBER`
   - Replace dates: `\\d{{4}}-\\d{{2}}-\\d{{2}}` → `DATE`
3. Generate signature: hash(normalized_message + level)
4. Check if signature exists in database
5. If NEW: Report error
6. Update signature database

**Save signatures**:
```bash
echo '<JSON>' > /tmp/bigquery_error_signatures_{project}_{dataset}_{table}.json
```

### Step 4: Display Results

**Output format**:
```
## {Skill Name} Error Scan

**Table**: {project}.{dataset}.{table}
**Time Window**: Last {N} hours
**Scan Time**: {current_timestamp}

### Results
Found {total} errors, {new} are NEW:

#### Error 1: {error_message}
- **{Identity Column}**: {id}
- **Level**: {level}
- **Timestamp**: {timestamp}
- **Status**: NEW ✨ / SEEN BEFORE

#### Error 2: ...
```

### Step 5: Offer Analysis

Ask user:
```
Found {N} new errors. What would you like to do?
1. Analyze for bugs (classify as BUG/EXPECTED/IMPROVEMENT)
2. Create Jira tickets for bugs
3. Show full error details
4. Nothing (just reporting)
```

If user wants analysis, invoke:
- `bug-analyzer` skill with error details
- Optionally: `auto-bug-detector` for full pipeline

## Example Usage

**User**: "Scan {skill_name} for bugs from last 6 hours"

**Skill**:
1. Queries `{project}.{dataset}.{table}`
2. Finds errors from last 6 hours
3. Checks error signatures
4. Reports NEW errors only
5. Asks if user wants analysis

## Schema Reference

**Table**: `{project}.{dataset}.{table}`

{LIST OF ALL COLUMNS AND TYPES FROM SCHEMA}

## Notes

- This skill was auto-generated on {generation_date}
- Generated by: bigquery-skill-builder meta-skill
- To regenerate with different configuration, run skill builder again
- Error signatures stored in: `/tmp/bigquery_error_signatures_{project}_{dataset}_{table}.json`
```

### Step 5: Confirm Completion

Display to user:
```
✅ Created monitoring skill: {skill_name}

**Location**: ~/.claude/skills/{skill_name}/SKILL.md

**Usage**:
"{skill_name}" or "Scan {skill_name} for bugs from last N hours"

**Configuration**:
- Table: {project}.{dataset}.{table}
- Error Column: {error_column}
- Timestamp: {timestamp_column}

The skill is ready to use! Try:
"Scan {skill_name} for bugs from last 4 hours"
```

## Error Handling

**If schema discovery fails**:
- Check BigQuery access permissions
- Verify table exists: `bq show {project}:{dataset}.{table}`
- Ask user to provide column names manually

**If skill directory already exists**:
- Ask user: "Skill {name} already exists. Overwrite?"
- If yes: proceed
- If no: ask for different name

## Example Session

```
User: "Create monitoring skill for qtco-messaging-channels.prod.app_logs"

Builder:
1. Queries schema for qtco-messaging-channels.prod.app_logs
2. Shows: "Found 30 columns: timestamp, level, message, error, ..."
3. Asks: "Which column contains errors?" → Detects "error"
4. Asks: "Which column is severity?" → Detects "level"
5. Asks: "Which column is timestamp?" → Detects "timestamp"
6. Asks: "Partition column?" → Detects "PARTITIONDATE"
7. Asks: "Identity column?" → Detects "request_id"
8. Asks: "Skill name?" → Suggests "app-logs-monitor"
9. Generates: ~/.claude/skills/app-logs-monitor/SKILL.md
10. Confirms: "✅ Created app-logs-monitor skill!"

User can now forever use:
"Scan app-logs-monitor for bugs"
```

## Privacy & Security

✅ Schema discovery queries column names only (no data access)
✅ User explicitly chooses which columns to configure
✅ Generated skill only queries specified columns
✅ Error signatures strip sensitive data (IDs, names, etc.)
❌ Never auto-queries all columns or proprietary fields

## Related Skills

After generating a monitoring skill, users can:
- Invoke the generated skill directly
- Use `bug-analyzer` on discovered errors
- Use `auto-bug-detector` for full pipeline
- Use `sender-management-jira-ticket-creator` for tickets
